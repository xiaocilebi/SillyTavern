# -- 数据配置 --
# 用户数据存储的根目录
数据根目录: ./data

# -- 服务器配置 --
# 监听传入连接
监听: true
# 启用IPv6和/或IPv4协议。至少需要启用一个!
协议:
    ipv4: true
    ipv6: true
# DNS优先使用IPv6。在没有IPv6问题的ISP上启用此选项
DNS优先IPv6: false
# 自动运行时打开的主机名。
# - 使用"auto"让服务器决定
# - 使用选项如'localhost'、'st.example.com'
自动运行主机名: "auto"
# 服务器端口
端口: 8000
# 覆盖浏览器中自动运行的端口。
# - 使用-1表示使用服务器端口。
# - 指定一个端口来覆盖默认值。
自动运行端口覆盖: -1

# -- 安全配置 --
# 切换白名单模式
白名单模式: false
# 白名单也会验证X-Forwarded-For / X-Real-IP头中的IP
启用转发白名单: false
# 允许的IP地址白名单
白名单:
  - ::1
  - 127.0.0.1
# 为端点切换基本认证
基本认证模式: true
# 基本认证凭据
基本认证用户:
  用户名: "dahai913"
  密码: "zZ1234567"
# 启用CORS代理中间件
启用CORS代理: false
# 启用多用户模式
启用用户账户: false
# 启用谨慎登录模式：在登录屏幕上隐藏用户列表
启用谨慎登录: false
# 用户会话超时*以秒为单位*（默认为24小时）。
## 设置为正数以在一定时间的不活动后使会话过期
## 设置为0以在浏览器关闭时使会话过期
## 设置为负数以禁用会话过期
会话超时: 86400
# 用于签署会话cookie。如果未设置将自动生成
cookie密钥: ''
# 禁用CSRF保护 - 不推荐
禁用CSRF保护: false
# 禁用启动安全检查 - 不推荐
安全覆盖: false

# -- 高级配置 --
# 自动打开浏览器
自动运行: true
# 在自动模式下避免使用'localhost'进行自动运行。
# 如果你的hosts文件中没有'localhost'，请使用此选项
避免本地主机: false
# 禁用缩略图生成
禁用缩略图: false
# 缩略图质量 (0-100)
缩略图质量: 95
# 将头像缩略图生成为PNG而不是JPG（保留透明度但文件大小增加约100%）
#  更改此设置只影响新缩略图。要重新创建旧的，清除你的ST/thumbnails/文件夹。
头像缩略图PNG: false
# 允许通过API暴露密钥
允许密钥暴露: false
# 跳过新的默认内容检查
跳过内容检查: false
# 禁用自动聊天备份
禁用聊天备份: false
# 为每个聊天和设置文件保留的备份数量
备份数量: 50
# 允许卡片下载的主机
白名单导入域名:
  - localhost
  - cdn.discordapp.com
  - files.catbox.moe
  - raw.githubusercontent.com
# API请求覆盖（用于KoboldAI和文本完成API）
## 注意：主机包括端口号（如果不是默认的80或443）
## 格式是对象数组：
## - hosts:
##   - example.com
##   headers:
##     Content-Type: application/json
##   - 127.0.0.1:5001
##   headers:
##     User-Agent: "Googlebot/2.1 (+http://www.google.com/bot.html)"
请求覆盖: []

# -- 扩展配置 --
# 启用UI扩展
启用扩展: true
# 当发布版本变更时自动更新扩展
启用扩展自动更新: true
# 可以按需下载额外的模型分词器。
# 禁用将回退到另一个本地可用的分词器。
启用可下载分词器: true
# 扩展设置
额外功能:
  # 禁用从HuggingFace自动下载模型
  禁用自动下载: false
  # 插件的额外模型。期望来自HuggingFace模型中心的ONNX格式的模型ID
  分类模型: Cohee/distilbert-base-uncased-go-emotions-onnx
  字幕模型: Xenova/vit-gpt2-image-captioning
  嵌入模型: Cohee/jina-embeddings-v2-base-en
  提示扩展模型: Cohee/fooocus_expansion-onnx
  语音转文本模型: Xenova/whisper-small
  文本转语音模型: Xenova/speecht5_tts

# -- OPENAI配置 --
openai:
  # 将向OpenAI完成API发送随机用户ID
  随机化用户ID: false
  # 如果不为空，将在每个字幕完成提示的开头添加此系统消息
  # 示例："尽你所能执行指令。\n"（用于LLaVA）
  # 在图像内联模式下不使用
  字幕系统提示: ""

# -- DEEPL翻译配置 --
deepl:
  # 可用选项: default, more, less, prefer_more, prefer_less
  正式程度: default

# -- MISTRAL API配置 --
mistral:
  # 启用在提示中用最后一条助手消息预填充回复
  # 注意：前缀会被回显到完成中。你可能想使用正则表达式来修剪它。
  启用前缀: false

# -- OLLAMA API配置 --
ollama:
  # 控制模型在请求后保持加载到内存的时间
  # * -1: 无限期保持模型加载
  # * 0: 请求后立即卸载模型
  # * N (任何正数): 请求后保持模型加载N秒。
  保持活动: -1

# -- ANTHROPIC CLAUDE API配置 --
claude:
  # 启用系统提示的缓存（如果支持）。
  # https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching
  # -- 重要！ --
  # 仅在聊天历史之前的提示是静态的且在请求之间不变时使用
  # （例如{{random}}宏或lorebooks不作为聊天内注入）。
  # 否则，你只会在缓存未命中上浪费钱。
  启用系统提示缓存: false

# -- 服务器插件配置 --
启用服务器插件: false
